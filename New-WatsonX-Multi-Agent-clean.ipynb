{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " # Basic Multi-agent Collaboration\n",
    "\n",
    " A single agent can usually operate effectively using a handful of tools within a single domain, but even using powerful models like `gpt-4`, it can be less effective at using many tools.\n",
    "\n",
    " One way to approach complicated tasks is through a \"divide-and-conquer\" approach: create an specialized agent for each task or domain and route tasks to the correct \"expert\".\n",
    "\n",
    " This notebook (inspired by the paper [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation](https://arxiv.org/abs/2308.08155), by Wu, et. al.) shows one way to do this using LangGraph.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting graph will look something like the following diagram:\n",
    "\n",
    "![multi_agent diagram](./img/simple_multi_agent_diagram.png)\n",
    "\n",
    "Before we get started, a quick note: this and other multi-agent notebooks are designed to show _how_ you can implement certain design patterns in LangGraph. If the pattern suits your needs, we recommend combining it with some of the other fundamental patterns described elsewhere in the docs for best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step 1 - Starting Tool Evaluation\n",
      "Step 1.1 self.bound_tools\n",
      "type(self.bound_tools) <class 'list'>\n",
      "self.bound_tools [TavilySearchResults(max_results=4)]\n",
      "Debug: Starting tool evaluation for input: Who is Ruslan Magana?\n",
      "tool_instances: [TavilySearchResults(max_results=4)]\n",
      "Debug: Result from tool tavily_search_results_json: [{'url': 'https://ruslanmv.com/about', 'content': \"I'm Ruslan Magana Vsevolodovna. I'm a Data Scientist, a Cloud Architect and a Physicist. About me. I am Data Scientist specializing in Artificial Intelligence, with a distinct focus on Neural Networks. My core expertise lies in Generative AI and prompt engineering. I possess a strong commitment to precision and boast an extensive track ...\"}, {'url': 'https://scholar.google.com/citations?user=rWBrOpwAAAAJ', 'content': 'Ruslan Magana Vsevolodovna. National Institute for Nuclear Physics. Verified email at ge.infn.it - Homepage. Nuclear Physics Machine Learning Data Science Cloud Computing Big Data. ... R Magana, H Zheng, A Bonasera. International Journal of Modern Physics E 21 (01), 1250006, 2012. 4: 2012:'}, {'url': 'https://medium.com/@ruslanmv', 'content': 'Read writing from Ruslan Magana Vsevolodovna on Medium. Machine Learning Engineer & Data Scientist & Physicist. Every day, Ruslan Magana Vsevolodovna and thousands of other voices read, write, and ...'}, {'url': 'https://it.linkedin.com/in/ruslanmv', 'content': 'Consigliato da Ruslan Magana Vsevolodovna, PhD. I am an expert in Artificial Intelligence with a focus on Neural Networks. My primary expertise lies in Generative AI and prompt engineering, with experience in the field of watsonx.ai. In my role, I am involved in researching, building, and designing artificial intelligence systems, specifically ...'}]\n",
      "Debug: Final combined output: WebSearch Results: I'm Ruslan Magana Vsevolodovna. I'm a Data Scientist, a Cloud Architect and a Physicist. About me. I am Data Scientist specializing in Artificial Intelligence, with a distinct focus on Neural Networks. My core expertise lies in Generative AI and prompt engineering. I possess a strong commitment to precision and boast an extensive track ... Ruslan Magana Vsevolodovna. National Institute for Nuclear Physics. Verified email at ge.infn.it - Homepage. Nuclear Physics Machine Learning Data Science Cloud Computing Big Data. ... R Magana, H Zheng, A Bonasera. International Journal of Modern Physics E 21 (01), 1250006, 2012. 4: 2012: Read writing from Ruslan Magana Vsevolodovna on Medium. Machine Learning Engineer & Data Scientist & Physicist. Every day, Ruslan Magana Vsevolodovna and thousands of other voices read, write, and ... Consigliato da Ruslan Magana Vsevolodovna, PhD. I am an expert in Artificial Intelligence with a focus on Neural Networks. My primary expertise lies in Generative AI and prompt engineering, with experience in the field of watsonx.ai. In my role, I am involved in researching, building, and designing artificial intelligence systems, specifically ...\n",
      "prompts [\"You are an assistant with access to web search results. Provide a detailed answer to the user's query.\\n\\nUser Query: Who is Ruslan Magana?\\n\\nUsing the information below:\\nWeb Search Results: WebSearch Results: I'm Ruslan Magana Vsevolodovna. I'm a Data Scientist, a Cloud Architect and a Physicist. About me. I am Data Scientist specializing in Artificial Intelligence, with a distinct focus on Neural Networks. My core expertise lies in Generative AI and prompt engineering. I possess a strong commitment to precision and boast an extensive track ... Ruslan Magana Vsevolodovna. National Institute for Nuclear Physics. Verified email at ge.infn.it - Homepage. Nuclear Physics Machine Learning Data Science Cloud Computing Big Data. ... R Magana, H Zheng, A Bonasera. International Journal of Modern Physics E 21 (01), 1250006, 2012. 4: 2012: Read writing from Ruslan Magana Vsevolodovna on Medium. Machine Learning Engineer & Data Scientist & Physicist. Every day, Ruslan Magana Vsevolodovna and thousands of other voices read, write, and ... Consigliato da Ruslan Magana Vsevolodovna, PhD. I am an expert in Artificial Intelligence with a focus on Neural Networks. My primary expertise lies in Generative AI and prompt engineering, with experience in the field of watsonx.ai. In my role, I am involved in researching, building, and designing artificial intelligence systems, specifically ...\\n\\n\"]\n",
      "Ruslan Magana Vsevolodovna is a Data Scientist, a Cloud Architect and a Physicist. Magana's primary expertise lies in Generative AI and prompt engineering. Magana is involved in researching, building, and designing artificial intelligence systems, specifically Watsonx.ai.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from typing import Any, Dict, List, Optional, Sequence, Type, Union, Callable, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_ibm import WatsonxLLM as BaseWatsonxLLM\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_core.outputs import LLMResult, Generation, GenerationChunk\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.language_models import LanguageModelInput\n",
    "from dotenv import load_dotenv\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Simplified loading of environment variables and IBM connection parameters\n",
    "load_dotenv()\n",
    "\n",
    "def set_env(var: str):\n",
    "    env_var = os.getenv(var)\n",
    "    if not env_var:\n",
    "        env_var = getpass.getpass(f\"{var}: \")\n",
    "        os.environ[var] = env_var\n",
    "    return env_var\n",
    "\n",
    "class IbmConnectionParams(BaseModel):\n",
    "    api_key: str\n",
    "    project_id: str\n",
    "    url: str\n",
    "    credentials: dict[str, str]\n",
    "\n",
    "    def __init__(self, api_key: str, project_id: str, url: str) -> None:\n",
    "        super().__init__(api_key=api_key, project_id=project_id, url=url, credentials={\"url\": url, \"apikey\": api_key})\n",
    "\n",
    "# Set IBM connection parameters\n",
    "ibm_params = IbmConnectionParams(\n",
    "    api_key=set_env(\"WATSONX_API_KEY\"),\n",
    "    project_id=set_env(\"PROJECT_ID\"),\n",
    "    url = set_env(\"WATSONX_URL\")\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.SAMPLE.value,\n",
    "    GenParams.MAX_NEW_TOKENS: 1000,\n",
    "    GenParams.MIN_NEW_TOKENS: 50,\n",
    "    GenParams.TEMPERATURE: 0.7,\n",
    "    GenParams.TOP_K: 50,\n",
    "    GenParams.TOP_P: 1\n",
    "}\n",
    "\n",
    "class WatsonxLLM(BaseWatsonxLLM):\n",
    "    \"\"\"Extended IBM watsonx.ai large language models.\"\"\"\n",
    "    # Define the default parameters as class variables\n",
    "    DEFAULT_MODEL_ID = \"ibm/granite-13b-instruct-v2\"\n",
    "    DEFAULT_URL = ibm_params.url\n",
    "    DEFAULT_APIKEY = ibm_params.api_key\n",
    "    DEFAULT_PROJECT_ID = ibm_params.project_id\n",
    "    DEFAULT_PARAMS = parameters    \n",
    "    bound_tools: Optional[List[BaseTool]] = Field(default=None, exclude=True)\n",
    "\n",
    "    def __init__(self, *args, tools: Optional[List[BaseTool]] = None, model_id: Optional[str] = None, **kwargs):\n",
    "        if not model_id and 'deployment_id' not in kwargs:\n",
    "            raise ValueError(\"One of 'model_id' or 'deployment_id' parameters should be set.\")\n",
    "        super().__init__(model_id=model_id, *args, **kwargs)\n",
    "        self.bound_tools = tools or []\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        prompts: List[str],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[Any] = None,\n",
    "        stream: Optional[bool] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> LLMResult:\n",
    "        params = self._get_chat_params(stop=stop)\n",
    "        should_stream = stream if stream is not None else self.streaming\n",
    "        if should_stream:\n",
    "            if len(prompts) > 1:\n",
    "                raise ValueError(f\"WatsonxLLM currently only supports single prompt, got {prompts}\")\n",
    "            generation = GenerationChunk(text=\"\")\n",
    "            stream_iter = self._stream(prompts[0], stop=stop, run_manager=run_manager, **kwargs)\n",
    "            for chunk in stream_iter:\n",
    "                if generation is None:\n",
    "                    generation = chunk\n",
    "                else:\n",
    "                    generation += chunk\n",
    "            assert generation is not None\n",
    "            if isinstance(generation.generation_info, dict):\n",
    "                llm_output = generation.generation_info.pop(\"llm_output\")\n",
    "                return LLMResult(generations=[[generation]], llm_output=llm_output)\n",
    "            return LLMResult(generations=[[generation]])\n",
    "        else:\n",
    "\n",
    "\n",
    "            print(\" Step 1 - Starting Tool Evaluation\")\n",
    "                       \n",
    "            if self.bound_tools:\n",
    "                print(\"Step 1.1 self.bound_tools\")\n",
    "                print(\"type(self.bound_tools)\",type(self.bound_tools)) \n",
    "                print(\"self.bound_tools\",self.bound_tools)\n",
    "                tool_output = self._evaluate_tools(self.bound_tools, prompts[0])\n",
    "                logger.info(\"Tool output: %s\", tool_output)\n",
    "\n",
    "                system_prompt = (\n",
    "                    f\"You are an assistant with access to web search results. \"\n",
    "                    f\"Provide a detailed answer to the user's query.\\n\\n\"\n",
    "                    f\"User Query: {prompts[0]}\\n\\n\"\n",
    "                    f\"Using the information below:\\n\"\n",
    "                    f\"Web Search Results: {tool_output}\\n\\n\"\n",
    "                )\n",
    "                prompts[0] = system_prompt\n",
    "\n",
    "            print(\"prompts\", prompts)\n",
    "\n",
    "            if not isinstance(params, dict):\n",
    "                raise ValueError(f\"Expected params to be a dictionary, got {type(params)}\")\n",
    "\n",
    "            response = self.watsonx_model.generate(\n",
    "                prompt=prompts, params=params, **kwargs\n",
    "            )\n",
    "            return self._create_llm_result(response)\n",
    "\n",
    "    def _evaluate_tools_old(self, tool_instances: List[BaseTool], input_text: str) -> str:\n",
    "        combined_output = []\n",
    "        for tool in tool_instances:\n",
    "            result = tool.invoke(input_text)\n",
    "            print(\"Result tool\", result)\n",
    "            \n",
    "            if isinstance(result, str):\n",
    "                content = \"WebSearch Results: \" + result\n",
    "            elif isinstance(result, list) and all(isinstance(item, dict) for item in result):\n",
    "                content = \"WebSearch Results: \" + \" \".join(item.get('content', '') for item in result)\n",
    "            else:\n",
    "                content = \"WebSearch Results: Invalid format received from tool\"\n",
    "\n",
    "            combined_output.append(content)\n",
    "        return \"\\n\\n\".join(combined_output)\n",
    "\n",
    "    def _evaluate_tools(self, tool_instances: List[BaseTool], input_text: str) -> str:\n",
    "        \"\"\"\n",
    "        Evaluate tools in sequence, processing their output and handling errors gracefully.\n",
    "        \"\"\"\n",
    "        combined_output = []\n",
    "        print(f\"Debug: Starting tool evaluation for input: {input_text}\")\n",
    "        print(\"tool_instances:\",tool_instances)\n",
    "\n",
    "        for tool in tool_instances:\n",
    "            try:\n",
    "                # Invoke the tool with the provided input\n",
    "                result = tool.invoke(input_text)\n",
    "                print(f\"Debug: Result from tool {tool.name}: {result}\")\n",
    "\n",
    "                # Check the type of result and handle it accordingly\n",
    "                if isinstance(result, str):\n",
    "                    # If the result is a string, we append it directly\n",
    "                    content = f\"WebSearch Results: {result}\"\n",
    "                elif isinstance(result, list) and all(isinstance(item, dict) for item in result):\n",
    "                    # Handle list of dictionaries (e.g., multiple search results)\n",
    "                    content = \"WebSearch Results: \" + \" \".join(item.get('content', '') for item in result)\n",
    "                elif isinstance(result, dict):\n",
    "                    # Handle dictionary response (single result, e.g., JSON response)\n",
    "                    content = \"WebSearch Results: \" + result.get('content', 'Unknown response format')\n",
    "                else:\n",
    "                    # If the format is unrecognized, note it as invalid\n",
    "                    content = \"WebSearch Results: Invalid format received from tool\"\n",
    "                \n",
    "                # Append the processed content to the combined output\n",
    "                combined_output.append(content)\n",
    "\n",
    "            except Exception as e:\n",
    "                # Gracefully handle any exceptions during the tool invocation\n",
    "                error_message = f\"Error invoking tool {tool.name}: {str(e)}\"\n",
    "                print(f\"Debug: {error_message}\")\n",
    "                combined_output.append(error_message)\n",
    "\n",
    "        # Combine the results from all tools and return the output\n",
    "        final_output = \"\\n\\n\".join(combined_output)\n",
    "        print(f\"Debug: Final combined output: {final_output}\")\n",
    "        return final_output\n",
    "        \n",
    "\n",
    "    @classmethod\n",
    "    def bind_tools(\n",
    "        cls,\n",
    "        tools: Sequence[Union[Dict[str, Any], Type[BaseModel], Callable, BaseTool]],\n",
    "        *,\n",
    "        model_id: Optional[str] = None,\n",
    "        url: Optional[str] = None,\n",
    "        apikey: Optional[str] = None,\n",
    "        project_id: Optional[str] = None,\n",
    "        params: Optional[Dict[str, Any]] = None,\n",
    "        tool_choice: Optional[Union[Dict[str, str], Literal[\"any\", \"auto\"], str]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> 'WatsonxLLM':\n",
    "        formatted_tools = [convert_to_openai_tool(tool)[\"function\"] for tool in tools]\n",
    "        # Initialize WatsonxLLM with the provided parameters\n",
    "        instance = cls(\n",
    "            model_id=model_id,\n",
    "            url=url,\n",
    "            apikey=apikey,\n",
    "            project_id=project_id,\n",
    "            params=params,\n",
    "            **kwargs\n",
    "        )\n",
    "        instance.bound_tools = tools\n",
    "        if tool_choice is not None:\n",
    "            kwargs[\"tool_choice\"] = tool_choice\n",
    "        return instance\n",
    "\n",
    "    def _create_llm_result(self, response: List[dict]) -> LLMResult:\n",
    "        generations = []\n",
    "        for res in response:\n",
    "            results = res.get(\"results\")\n",
    "            if results:\n",
    "                finish_reason = results[0].get(\"stop_reason\")\n",
    "                gen = Generation(\n",
    "                    text=results[0].get(\"generated_text\"),\n",
    "                    generation_info={\"finish_reason\": finish_reason},\n",
    "                )\n",
    "                generations.append([gen])\n",
    "        final_token_usage = self._extract_token_usage(response)\n",
    "        llm_output = {\n",
    "            \"token_usage\": final_token_usage,\n",
    "            \"model_id\": self.model_id,\n",
    "            \"deployment_id\": self.deployment_id,\n",
    "        }\n",
    "        return LLMResult(generations=generations, llm_output=llm_output)\n",
    "\n",
    "# Example usage:\n",
    "tool = TavilySearchResults(max_results=4)\n",
    "\n",
    "# Bind the tool and pass all necessary parameters inside `bind_tools`\n",
    "llm_with_tools = WatsonxLLM.bind_tools(\n",
    "    tools=[tool],\n",
    "    model_id=\"ibm/granite-13b-instruct-v2\",\n",
    "    url=ibm_params.url,\n",
    "    apikey=ibm_params.api_key,\n",
    "    project_id=ibm_params.project_id,\n",
    "    params=parameters\n",
    ")\n",
    "# Invoke the model\n",
    "response = llm_with_tools.invoke(\"Who is Ruslan Magana?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step 1 - Starting Tool Evaluation\n",
      "Step 1.1 self.bound_tools\n",
      "type(self.bound_tools) <class 'list'>\n",
      "self.bound_tools [TavilySearchResults(max_results=4)]\n",
      "Debug: Starting tool evaluation for input: Who is Ruslan Magana?\n",
      "Debug: Result from tool tavily_search_results_json: [{'url': 'https://ruslanmv.com/about', 'content': \"I'm Ruslan Magana Vsevolodovna. I'm a Data Scientist, a Cloud Architect and a Physicist. About me. I am Data Scientist specializing in Artificial Intelligence, with a distinct focus on Neural Networks. My core expertise lies in Generative AI and prompt engineering. I possess a strong commitment to precision and boast an extensive track ...\"}, {'url': 'https://scholar.google.com/citations?user=rWBrOpwAAAAJ', 'content': 'Ruslan Magana Vsevolodovna. National Institute for Nuclear Physics. Verified email at ge.infn.it - Homepage. Nuclear Physics Machine Learning Data Science Cloud Computing Big Data. ... R Magana, H Zheng, A Bonasera. International Journal of Modern Physics E 21 (01), 1250006, 2012. 4: 2012:'}, {'url': 'https://it.linkedin.com/in/ruslanmv', 'content': 'Consigliato da Ruslan Magana Vsevolodovna, PhD. I am an expert in Artificial Intelligence with a focus on Neural Networks. My primary expertise lies in Generative AI and prompt engineering, with experience in the field of watsonx.ai. In my role, I am involved in researching, building, and designing artificial intelligence systems, specifically ...'}, {'url': 'https://ruslanmv.com/blog/Mathematics-of-a-Basic-Generative-Pretrained-Transformer', 'content': 'Ruslan Magana Vsevolodovna. Projects; Certifications; Publications; Talks; About; Toggle menu. Generative AI is the most powerful tool for creativity that has ever been created. It has the potential to unleash a new era of human innovation. ~Elon Musk Ruslan Magana Vsevolodovna.'}]\n",
      "Debug: Final combined output: WebSearch Results: I'm Ruslan Magana Vsevolodovna. I'm a Data Scientist, a Cloud Architect and a Physicist. About me. I am Data Scientist specializing in Artificial Intelligence, with a distinct focus on Neural Networks. My core expertise lies in Generative AI and prompt engineering. I possess a strong commitment to precision and boast an extensive track ... Ruslan Magana Vsevolodovna. National Institute for Nuclear Physics. Verified email at ge.infn.it - Homepage. Nuclear Physics Machine Learning Data Science Cloud Computing Big Data. ... R Magana, H Zheng, A Bonasera. International Journal of Modern Physics E 21 (01), 1250006, 2012. 4: 2012: Consigliato da Ruslan Magana Vsevolodovna, PhD. I am an expert in Artificial Intelligence with a focus on Neural Networks. My primary expertise lies in Generative AI and prompt engineering, with experience in the field of watsonx.ai. In my role, I am involved in researching, building, and designing artificial intelligence systems, specifically ... Ruslan Magana Vsevolodovna. Projects; Certifications; Publications; Talks; About; Toggle menu. Generative AI is the most powerful tool for creativity that has ever been created. It has the potential to unleash a new era of human innovation. ~Elon Musk Ruslan Magana Vsevolodovna.\n",
      "prompts [\"You are an assistant with access to web search results. Provide a detailed answer to the user's query.\\n\\nUser Query: Who is Ruslan Magana?\\n\\nUsing the information below:\\nWeb Search Results: WebSearch Results: I'm Ruslan Magana Vsevolodovna. I'm a Data Scientist, a Cloud Architect and a Physicist. About me. I am Data Scientist specializing in Artificial Intelligence, with a distinct focus on Neural Networks. My core expertise lies in Generative AI and prompt engineering. I possess a strong commitment to precision and boast an extensive track ... Ruslan Magana Vsevolodovna. National Institute for Nuclear Physics. Verified email at ge.infn.it - Homepage. Nuclear Physics Machine Learning Data Science Cloud Computing Big Data. ... R Magana, H Zheng, A Bonasera. International Journal of Modern Physics E 21 (01), 1250006, 2012. 4: 2012: Consigliato da Ruslan Magana Vsevolodovna, PhD. I am an expert in Artificial Intelligence with a focus on Neural Networks. My primary expertise lies in Generative AI and prompt engineering, with experience in the field of watsonx.ai. In my role, I am involved in researching, building, and designing artificial intelligence systems, specifically ... Ruslan Magana Vsevolodovna. Projects; Certifications; Publications; Talks; About; Toggle menu. Generative AI is the most powerful tool for creativity that has ever been created. It has the potential to unleash a new era of human innovation. ~Elon Musk Ruslan Magana Vsevolodovna.\\n\\n\"]\n",
      "Ruslan Magana Vsevolodovna is a Data Scientist, a Cloud Architect and a Physicist. Ruslan Magana Vsevolodovna is an expert in Artificial Intelligence with a focus on Neural Networks. Ruslan Magana Vsevolodovna's primary expertise lies in Generative AI and prompt engineering. Ruslan Magana Vsevolodovna is involved in researching, building, and designing artificial intelligence systems, specifically Watsonx.ai.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "tool = TavilySearchResults(max_results=4)\n",
    "llm_with_tools = WatsonxLLM.bind_tools(\n",
    "    tools=[tool],\n",
    "    model_id=\"ibm/granite-13b-instruct-v2\",\n",
    "    url=ibm_params.url,\n",
    "    apikey=ibm_params.api_key,\n",
    "    project_id=ibm_params.project_id,\n",
    "    params=parameters    \n",
    ")  \n",
    "response = llm_with_tools.invoke(\"Who is Ruslan Magana?\")\n",
    "print(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "def create_agent(llm, tools, system_message: str):\n",
    "    \"\"\"Create an agent.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "                \" Use the provided tools to progress towards answering the question.\"\n",
    "                \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "                \" will help where you left off. Execute what you can to make progress.\"\n",
    "                \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "                \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "                \" You have access to the following tools: {tool_names}.\\n{system_message}\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(system_message=system_message)\n",
    "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "    print(\"Tools defined:\", tools)\n",
    "    return prompt | llm.bind_tools(     \n",
    "        tools,\n",
    "        model_id=\"ibm/granite-13b-instruct-v2\",\n",
    "        url=ibm_params.url,\n",
    "        apikey=ibm_params.api_key,\n",
    "        project_id=ibm_params.project_id,\n",
    "        params=parameters  \n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import Annotated\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily_tool = TavilySearchResults(max_results=4)\n",
    "# Warning: This executes code locally, which can be unsafe when not sandboxed\n",
    "repl = PythonREPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def python_repl(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"]\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    result_str = f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
    "    return (\n",
    "        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Create graph\n",
    "import functools\n",
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create a node for a given agent\n",
    "def agent_node_old(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    # We convert the agent output into a format that is suitable to append to the global state\n",
    "    if isinstance(result, ToolMessage):\n",
    "        pass\n",
    "    else:\n",
    "        result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "    return {\n",
    "        \"messages\": [result],\n",
    "        \"sender\": name,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    # Check if result has a dict method (indicating it's not a simple string)\n",
    "    if hasattr(result, 'dict'):\n",
    "        # If it's an object with a dict method, convert it to the appropriate format\n",
    "        result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "    else:\n",
    "        # If result is a string, construct an AIMessage with the text\n",
    "        result = AIMessage(content=str(result), name=name)\n",
    "    return {\n",
    "        \"messages\": [result],\n",
    "        \"sender\": name,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools defined: [TavilySearchResults(max_results=4)]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# Research agent and node\n",
    "research_agent = create_agent(\n",
    "    WatsonxLLM,\n",
    "    [tavily_tool],\n",
    "    system_message=\"You should provide accurate data for the chart_generator to use.\",\n",
    ")\n",
    "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools defined: [StructuredTool(name='python_repl', description='Use this to execute python code. If you want to see the output of a value,\\n    you should print it out with `print(...)`. This is visible to the user.', args_schema=<class 'pydantic.v1.main.python_replSchema'>, func=<function python_repl at 0x7f1f9d074af0>)]\n"
     ]
    }
   ],
   "source": [
    "# chart_generator\n",
    "chart_agent = create_agent(\n",
    "    WatsonxLLM,\n",
    "    [python_repl],\n",
    "    system_message=\"Any charts you display will be visible by the user.\",\n",
    ")\n",
    "chart_node = functools.partial(agent_node, agent=chart_agent, name=\"chart_generator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TavilySearchResults(max_results=4), StructuredTool(name='python_repl', description='Use this to execute python code. If you want to see the output of a value,\\n    you should print it out with `print(...)`. This is visible to the user.', args_schema=<class 'pydantic.v1.main.python_replSchema'>, func=<function python_repl at 0x7f1f9d074af0>)]\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "tools = [tavily_tool, python_repl]\n",
    "tool_node = ToolNode(tools)\n",
    "print(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tools(recurse=True, tools_by_name={'tavily_search_results_json': TavilySearchResults(max_results=4), 'python_repl': StructuredTool(name='python_repl', description='Use this to execute python code. If you want to see the output of a value,\\n    you should print it out with `print(...)`. This is visible to the user.', args_schema=<class 'pydantic.v1.main.python_replSchema'>, func=<function python_repl at 0x7f1f9d074af0>)}, handle_tool_errors=True)\n"
     ]
    }
   ],
   "source": [
    "print(tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Define Edge Logic\n",
    "# %%\n",
    "from typing import Literal\n",
    "def router(state) -> Literal[\"call_tool\", \"__end__\", \"continue\"]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"call_tool\"\n",
    "    if \"FINAL ANSWER\" in last_message.content:\n",
    "        return \"__end__\"\n",
    "    return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "# This defines the object that is passed between each node\n",
    "# in the graph. We will create different nodes for each agent and tool\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    sender: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "# ## Define the Graph\n",
    "# %%\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Researcher\", research_node)\n",
    "workflow.add_node(\"chart_generator\", chart_node)\n",
    "workflow.add_node(\"call_tool\", tool_node)\n",
    "workflow.add_conditional_edges(\n",
    "    \"Researcher\",\n",
    "    router,\n",
    "    {\"continue\": \"chart_generator\", \"call_tool\": \"call_tool\", \"__end__\": END},\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"chart_generator\",\n",
    "    router,\n",
    "    {\"continue\": \"Researcher\", \"call_tool\": \"call_tool\", \"__end__\": END},\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"call_tool\",\n",
    "    lambda x: x[\"sender\"],\n",
    "    {\n",
    "        \"Researcher\": \"Researcher\",\n",
    "        \"chart_generator\": \"chart_generator\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the graph is initialized properly with a valid entry point\n",
    "workflow.set_entry_point(\"Researcher\")  # Set the entry point of the graph\n",
    "# Compile the workflow to prepare it for execution\n",
    "graph = workflow.compile()\n",
    "from IPython.display import Image, display\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    ToolMessage,\n",
    "    HumanMessage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step 1 - Starting Tool Evaluation\n",
      "Step 1.1 self.bound_tools\n",
      "type(self.bound_tools) <class 'list'>\n",
      "self.bound_tools [TavilySearchResults(max_results=4)]\n",
      "Debug: Starting tool evaluation for input: System: You are a helpful AI assistant, collaborating with other assistants. Use the provided tools to progress towards answering the question. If you are unable to fully answer, that's OK, another assistant with different tools  will help where you left off. Execute what you can to make progress. If you or any of the other assistants have the final answer or deliverable, prefix your response with FINAL ANSWER so the team knows to stop. You have access to the following tools: tavily_search_results_json.\n",
      "You should provide accurate data for the chart_generator to use.\n",
      "Human: Fetch the UK's GDP over the past 5 years, then draw a line graph of it. Once you code it up, finish.\n",
      "tool_instances: [TavilySearchResults(max_results=4)]\n",
      "Debug: Result from tool tavily_search_results_json: HTTPError('400 Client Error: Bad Request for url: https://api.tavily.com/search')\n",
      "Debug: Final combined output: WebSearch Results: HTTPError('400 Client Error: Bad Request for url: https://api.tavily.com/search')\n",
      "prompts [\"You are an assistant with access to web search results. Provide a detailed answer to the user's query.\\n\\nUser Query: System: You are a helpful AI assistant, collaborating with other assistants. Use the provided tools to progress towards answering the question. If you are unable to fully answer, that's OK, another assistant with different tools  will help where you left off. Execute what you can to make progress. If you or any of the other assistants have the final answer or deliverable, prefix your response with FINAL ANSWER so the team knows to stop. You have access to the following tools: tavily_search_results_json.\\nYou should provide accurate data for the chart_generator to use.\\nHuman: Fetch the UK's GDP over the past 5 years, then draw a line graph of it. Once you code it up, finish.\\n\\nUsing the information below:\\nWeb Search Results: WebSearch Results: HTTPError('400 Client Error: Bad Request for url: https://api.tavily.com/search')\\n\\n\"]\n",
      "{'Researcher': {'messages': [AIMessage(content='\\n FINAL ANSWER:Bad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request\\n\\n\\n\\nBad Request ', name='Researcher')], 'sender': 'Researcher'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"Fetch the UK's GDP over the past 5 years,\"\n",
    "                \" then draw a line graph of it.\"\n",
    "                \" Once you code it up, finish.\"\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    # Maximum number of steps to take in the graph\n",
    "    {\"recursion_limit\": 150},\n",
    ")\n",
    "for s in events:\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate_tools_debugg(tool_instances: List[BaseTool], input_text: str) -> str:\n",
    "    \"\"\"\n",
    "    A debug-friendly version of _evaluate_tools that handles various output types,\n",
    "    logs detailed information, and gracefully handles errors.\n",
    "    \"\"\"\n",
    "    combined_output = []\n",
    "    print(f\"Debug: Starting tool evaluation for input: {input_text}\")\n",
    "\n",
    "    for tool in tool_instances:\n",
    "        try:\n",
    "            # Invoke the tool with the provided input\n",
    "            result = tool.invoke(input_text)\n",
    "            print(f\"Debug: Result from tool {tool.name}: {result}\")\n",
    "\n",
    "            if isinstance(result, str):\n",
    "                # If the result is a simple string, append it\n",
    "                content = f\"WebSearch Results: {result}\"\n",
    "            elif isinstance(result, list) and all(isinstance(item, dict) for item in result):\n",
    "                # Handle a list of dicts (e.g., multiple search results)\n",
    "                content = \"WebSearch Results: \" + \" \".join(item.get('content', '') for item in result)\n",
    "            elif isinstance(result, dict):\n",
    "                # Handle a single dict response (e.g., JSON format)\n",
    "                content = \"WebSearch Results: \" + result.get('content', 'Unknown response format')\n",
    "            else:\n",
    "                # If the format is not recognized, append a message indicating an invalid format\n",
    "                content = \"WebSearch Results: Invalid format received from tool\"\n",
    "            \n",
    "            # Append the processed content to the combined output\n",
    "            combined_output.append(content)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Gracefully handle any exceptions during the tool invocation\n",
    "            error_message = f\"Error invoking tool {tool.name}: {str(e)}\"\n",
    "            print(f\"Debug: {error_message}\")\n",
    "            combined_output.append(error_message)\n",
    "\n",
    "    # Return the combined results from all tools, joined by newlines\n",
    "    final_output = \"\\n\\n\".join(combined_output)\n",
    "    print(f\"Debug: Final combined output: {final_output}\")\n",
    "    return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Starting tool evaluation for input: Who is Ruslan Magana?\n",
      "Debug: Result from tool tavily_search_results_json: [{'url': 'https://ruslanmv.com/about', 'content': \"I'm Ruslan Magana Vsevolodovna. I'm a Data Scientist, a Cloud Architect and a Physicist. About me. I am Data Scientist specializing in Artificial Intelligence, with a distinct focus on Neural Networks. My core expertise lies in Generative AI and prompt engineering. I possess a strong commitment to precision and boast an extensive track ...\"}, {'url': 'https://scholar.google.com/citations?user=rWBrOpwAAAAJ', 'content': 'Ruslan Magana Vsevolodovna. National Institute for Nuclear Physics. Verified email at ge.infn.it - Homepage. Nuclear Physics Machine Learning Data Science Cloud Computing Big Data. ... R Magana, H Zheng, A Bonasera. International Journal of Modern Physics E 21 (01), 1250006, 2012. 4: 2012:'}, {'url': 'https://www.linkedin.com/posts/ruslanmv_watsonxgovernance-technical-sales-intermediate-activity-7192621868636323840-YmBn', 'content': 'Ruslan Magana Vsevolodovna, PhD Data Scientist 1mo Report this post üëã Hello everyone! I have just published a simple post about how to build a simple Medical Chatbot üè•üí¨ using a custom LLM ...'}, {'url': 'https://medium.com/@ruslanmv', 'content': 'Read writing from Ruslan Magana Vsevolodovna on Medium. Machine Learning Engineer & Data Scientist & Physicist. Every day, Ruslan Magana Vsevolodovna and thousands of other voices read, write, and ...'}]\n",
      "Debug: Final combined output: WebSearch Results: I'm Ruslan Magana Vsevolodovna. I'm a Data Scientist, a Cloud Architect and a Physicist. About me. I am Data Scientist specializing in Artificial Intelligence, with a distinct focus on Neural Networks. My core expertise lies in Generative AI and prompt engineering. I possess a strong commitment to precision and boast an extensive track ... Ruslan Magana Vsevolodovna. National Institute for Nuclear Physics. Verified email at ge.infn.it - Homepage. Nuclear Physics Machine Learning Data Science Cloud Computing Big Data. ... R Magana, H Zheng, A Bonasera. International Journal of Modern Physics E 21 (01), 1250006, 2012. 4: 2012: Ruslan Magana Vsevolodovna, PhD Data Scientist 1mo Report this post üëã Hello everyone! I have just published a simple post about how to build a simple Medical Chatbot üè•üí¨ using a custom LLM ... Read writing from Ruslan Magana Vsevolodovna on Medium. Machine Learning Engineer & Data Scientist & Physicist. Every day, Ruslan Magana Vsevolodovna and thousands of other voices read, write, and ...\n",
      "Test Result:\n",
      "WebSearch Results: I'm Ruslan Magana Vsevolodovna. I'm a Data Scientist, a Cloud Architect and a Physicist. About me. I am Data Scientist specializing in Artificial Intelligence, with a distinct focus on Neural Networks. My core expertise lies in Generative AI and prompt engineering. I possess a strong commitment to precision and boast an extensive track ... Ruslan Magana Vsevolodovna. National Institute for Nuclear Physics. Verified email at ge.infn.it - Homepage. Nuclear Physics Machine Learning Data Science Cloud Computing Big Data. ... R Magana, H Zheng, A Bonasera. International Journal of Modern Physics E 21 (01), 1250006, 2012. 4: 2012: Ruslan Magana Vsevolodovna, PhD Data Scientist 1mo Report this post üëã Hello everyone! I have just published a simple post about how to build a simple Medical Chatbot üè•üí¨ using a custom LLM ... Read writing from Ruslan Magana Vsevolodovna on Medium. Machine Learning Engineer & Data Scientist & Physicist. Every day, Ruslan Magana Vsevolodovna and thousands of other voices read, write, and ...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Example tool instance (TavilySearchResults)\n",
    "tool = TavilySearchResults(max_results=4)\n",
    "\n",
    "# Test input for the tool invocation\n",
    "test_input = \"Who is Ruslan Magana?\"\n",
    "\n",
    "# Test _evaluate_tools_debugg with the TavilySearchResults tool\n",
    "result = _evaluate_tools_debugg([tool], test_input)\n",
    "\n",
    "# Output the result of the test\n",
    "print(\"Test Result:\")\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
