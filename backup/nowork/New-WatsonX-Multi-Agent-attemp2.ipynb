{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " # Basic Multi-agent Collaboration\n",
    "\n",
    " A single agent can usually operate effectively using a handful of tools within a single domain, but even using powerful models like `gpt-4`, it can be less effective at using many tools.\n",
    "\n",
    " One way to approach complicated tasks is through a \"divide-and-conquer\" approach: create an specialized agent for each task or domain and route tasks to the correct \"expert\".\n",
    "\n",
    " This notebook (inspired by the paper [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation](https://arxiv.org/abs/2308.08155), by Wu, et. al.) shows one way to do this using LangGraph.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting graph will look something like the following diagram:\n",
    "\n",
    "![multi_agent diagram](./img/simple_multi_agent_diagram.png)\n",
    "\n",
    "Before we get started, a quick note: this and other multi-agent notebooks are designed to show _how_ you can implement certain design patterns in LangGraph. If the pattern suits your needs, we recommend combining it with some of the other fundamental patterns described elsewhere in the docs for best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompts ['How is the weather in Genova']\n",
      "?The weather in Genoa is usually mild, with temperatures ranging from 15 to 26 degrees Celsius. The city is known for its Ligurian cuisine, which is based on vegetables, fruits, olive oil, and seafood. icing on the cake\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from typing import Any, Dict, List, Optional, Sequence, Type, Union, Callable, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_ibm import WatsonxLLM as BaseWatsonxLLM\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_core.outputs import LLMResult, Generation, GenerationChunk\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.language_models import LanguageModelInput\n",
    "from dotenv import load_dotenv\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class WatsonxLLM(BaseWatsonxLLM):\n",
    "    \"\"\"Extended IBM watsonx.ai large language models.\"\"\"\n",
    "\n",
    "    bound_tools: Optional[List[BaseTool]] = Field(default=None, exclude=True)\n",
    "\n",
    "    def __init__(self, *args, tools: Optional[List[BaseTool]] = None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.bound_tools = tools or []\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        prompts: List[str],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[Any] = None,\n",
    "        stream: Optional[bool] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> LLMResult:\n",
    "        \"\"\"Call the IBM watsonx.ai inference endpoint which then generates the response.\"\"\"\n",
    "        params = self._get_chat_params(stop=stop)\n",
    "        should_stream = stream if stream is not None else self.streaming\n",
    "        if should_stream:\n",
    "            if len(prompts) > 1:\n",
    "                raise ValueError(f\"WatsonxLLM currently only supports single prompt, got {prompts}\")\n",
    "            generation = GenerationChunk(text=\"\")\n",
    "            stream_iter = self._stream(prompts[0], stop=stop, run_manager=run_manager, **kwargs)\n",
    "            for chunk in stream_iter:\n",
    "                if generation is None:\n",
    "                    generation = chunk\n",
    "                else:\n",
    "                    generation += chunk\n",
    "            assert generation is not None\n",
    "            if isinstance(generation.generation_info, dict):\n",
    "                llm_output = generation.generation_info.pop(\"llm_output\")\n",
    "                return LLMResult(generations=[[generation]], llm_output=llm_output)\n",
    "            return LLMResult(generations=[[generation]])\n",
    "        else:\n",
    "            # Apply tools before generation\n",
    "            if self.bound_tools:\n",
    "                tool_output = self._evaluate_tools(self.bound_tools, prompts[0])\n",
    "                logger.info(\"Tool output: %s\", tool_output)\n",
    "\n",
    "                system_prompt = (\n",
    "                    f\"You are an assistant with access to web search results. \"\n",
    "                    f\"Provide a detailed answer to the user's query.\\n\\n\"\n",
    "                    f\"User Query: {prompts[0]}\\n\\n\"\n",
    "                    f\"Using the information below:\\n\"\n",
    "                    f\"Web Search Results: {tool_output}\\n\\n\"\n",
    "                )\n",
    "                prompts[0] = system_prompt\n",
    "\n",
    "            print(\"prompts\", prompts)\n",
    "\n",
    "            # Ensure that params is passed as a dictionary\n",
    "            if not isinstance(params, dict):\n",
    "                raise ValueError(f\"Expected params to be a dictionary, got {type(params)}\")\n",
    "\n",
    "            response = self.watsonx_model.generate(\n",
    "                prompt=prompts, params=params, **kwargs\n",
    "            )\n",
    "            return self._create_llm_result(response)\n",
    "\n",
    "    def _evaluate_tools(self, tool_instances: List[BaseTool], input_text: str) -> str:\n",
    "        \"\"\"Evaluate the provided tools and return their combined output.\"\"\"\n",
    "        combined_output = []\n",
    "        for tool in tool_instances:\n",
    "            result = tool.invoke(input_text)\n",
    "            print(\"Result tool\",result)\n",
    "            #content = \"WebSearch Results: \" + \" \".join(result['content'] for result in result)\n",
    "            \n",
    "            # Check if the result is a string, if so, use it directly\n",
    "            if isinstance(result, str):\n",
    "                content = \"WebSearch Results: \" + result\n",
    "            # Otherwise, handle the case where it's a list of dictionaries (or similar structure)\n",
    "            elif isinstance(result, list) and all(isinstance(item, dict) for item in result):\n",
    "                content = \"WebSearch Results: \" + \" \".join(item.get('content', '') for item in result)\n",
    "            else:\n",
    "                # Handle other unexpected cases (fallback)\n",
    "                content = \"WebSearch Results: Invalid format received from tool\"\n",
    "            \n",
    "\n",
    "\n",
    "            combined_output.append(content)\n",
    "        return \"\\n\\n\".join(combined_output)\n",
    "\n",
    "    @classmethod\n",
    "    def bind_tools(\n",
    "        cls,\n",
    "        tools: Sequence[Union[Dict[str, Any], Type[BaseModel], Callable, BaseTool]],\n",
    "        *,\n",
    "        tool_choice: Optional[Union[Dict[str, str], Literal[\"any\", \"auto\"], str]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> 'WatsonxLLM':\n",
    "        \"\"\"Bind tool-like objects to this chat model.\"\"\"\n",
    "        formatted_tools = [convert_to_openai_tool(tool)[\"function\"] for tool in tools]\n",
    "        instance = cls(**kwargs)\n",
    "        instance.bound_tools = tools\n",
    "        if tool_choice is not None:\n",
    "            kwargs[\"tool_choice\"] = tool_choice\n",
    "        return instance\n",
    "\n",
    "    def _create_llm_result(self, response: List[dict]) -> LLMResult:\n",
    "        \"\"\"Create the LLMResult from the choices and prompts.\"\"\"\n",
    "        generations = []\n",
    "        for res in response:\n",
    "            results = res.get(\"results\")\n",
    "            if results:\n",
    "                finish_reason = results[0].get(\"stop_reason\")\n",
    "                gen = Generation(\n",
    "                    text=results[0].get(\"generated_text\"),\n",
    "                    generation_info={\"finish_reason\": finish_reason},\n",
    "                )\n",
    "                generations.append([gen])\n",
    "        final_token_usage = self._extract_token_usage(response)\n",
    "        llm_output = {\n",
    "            \"token_usage\": final_token_usage,\n",
    "            \"model_id\": self.model_id,\n",
    "            \"deployment_id\": self.deployment_id,\n",
    "        }\n",
    "        return LLMResult(generations=generations, llm_output=llm_output)\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    load_dotenv()  # Load environment variables from .env file\n",
    "    env_var = os.getenv(var)\n",
    "    if not env_var:\n",
    "        env_var = getpass.getpass(f\"{var}: \")\n",
    "        os.environ[var] = env_var\n",
    "    return env_var\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "api_key = _set_env(\"WATSONX_API_KEY\")\n",
    "project_id = _set_env(\"PROJECT_ID\")\n",
    "url = _set_env(\"WATSONX_URL\")\n",
    "\n",
    "# WatsonxLLM initialization\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.SAMPLE.value,\n",
    "    GenParams.MAX_NEW_TOKENS: 1000,\n",
    "    GenParams.MIN_NEW_TOKENS: 50,\n",
    "    GenParams.TEMPERATURE: 0.7,\n",
    "    GenParams.TOP_K: 50,\n",
    "    GenParams.TOP_P: 1\n",
    "}\n",
    "model_id = \"ibm/granite-13b-instruct-v2\"\n",
    "watsonx_instance = WatsonxLLM(\n",
    "    model_id=model_id,\n",
    "    url=url,\n",
    "    apikey=api_key,\n",
    "    project_id=project_id,\n",
    "    params=parameters  # params passed as a dictionary\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "response = watsonx_instance.invoke(\"How is the weather in Genova\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result tool [{'url': 'https://ruslanmv.com/about', 'content': \"I'm Ruslan Magana Vsevolodovna. I'm a Data Scientist, a Cloud Architect and a Physicist. About me. I am Data Scientist specializing in Artificial Intelligence, with a distinct focus on Neural Networks. My core expertise lies in Generative AI and prompt engineering. I possess a strong commitment to precision and boast an extensive track ...\"}, {'url': 'https://scholar.google.com/citations?user=rWBrOpwAAAAJ', 'content': 'Ruslan Magana Vsevolodovna. National Institute for Nuclear Physics. Verified email at ge.infn.it - Homepage. Nuclear Physics Machine Learning Data Science Cloud Computing Big Data. ... R Magana, H Zheng, A Bonasera. International Journal of Modern Physics E 21 (01), 1250006, 2012. 4: 2012:'}, {'url': 'https://it.linkedin.com/in/ruslanmv', 'content': 'Consigliato da Ruslan Magana Vsevolodovna, PhD. I am an expert in Artificial Intelligence with a focus on Neural Networks. My primary expertise lies in Generative AI and prompt engineering, with experience in the field of watsonx.ai. In my role, I am involved in researching, building, and designing artificial intelligence systems, specifically ...'}, {'url': 'https://independent.academia.edu/ruslanmv', 'content': 'by Ruslan Magana Vsevolodovna. Publisher: UniversitÃ  degli studi di Genova Publication Date: Mar 26, 2018. Research Interests: Physics, Nuclear Physics, and Neutrinoless Double Beta Decay.'}]\n",
      "prompts [\"You are an assistant with access to web search results. Provide a detailed answer to the user's query.\\n\\nUser Query: Who is Ruslan Magana?\\n\\nUsing the information below:\\nWeb Search Results: WebSearch Results: I'm Ruslan Magana Vsevolodovna. I'm a Data Scientist, a Cloud Architect and a Physicist. About me. I am Data Scientist specializing in Artificial Intelligence, with a distinct focus on Neural Networks. My core expertise lies in Generative AI and prompt engineering. I possess a strong commitment to precision and boast an extensive track ... Ruslan Magana Vsevolodovna. National Institute for Nuclear Physics. Verified email at ge.infn.it - Homepage. Nuclear Physics Machine Learning Data Science Cloud Computing Big Data. ... R Magana, H Zheng, A Bonasera. International Journal of Modern Physics E 21 (01), 1250006, 2012. 4: 2012: Consigliato da Ruslan Magana Vsevolodovna, PhD. I am an expert in Artificial Intelligence with a focus on Neural Networks. My primary expertise lies in Generative AI and prompt engineering, with experience in the field of watsonx.ai. In my role, I am involved in researching, building, and designing artificial intelligence systems, specifically ... by Ruslan Magana Vsevolodovna. Publisher: UniversitÃ  degli studi di Genova Publication Date: Mar 26, 2018. Research Interests: Physics, Nuclear Physics, and Neutrinoless Double Beta Decay.\\n\\n\"]\n",
      " Ruslan Magana Vsevolodovna is a Data Scientist, Cloud Architect and Physicist. Ruslan Magana Vsevolodovna is the Head of the Nuclear Physics Group at the National Institute for Nuclear Physics. Ruslan Magana Vsevolodovna is also an expert in Artificial Intelligence with a focus on Neural Networks.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "tool = TavilySearchResults(max_results=4)\n",
    "llm_with_tools = watsonx_instance.bind_tools(tools=[tool],model_id=model_id,url=url,apikey=api_key,project_id=project_id,params=parameters)  \n",
    "response = llm_with_tools.invoke(\"Who is Ruslan Magana?\")\n",
    "print(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Any, Dict, List, Optional, Sequence, Type, Union, Callable, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_ibm import WatsonxLLM as BaseWatsonxLLM\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_core.outputs import LLMResult, Generation, GenerationChunk\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.language_models import LanguageModelInput\n",
    "from dotenv import load_dotenv\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Simplified loading of environment variables and IBM connection parameters\n",
    "load_dotenv()\n",
    "\n",
    "def set_env(var: str):\n",
    "    env_var = os.getenv(var)\n",
    "    if not env_var:\n",
    "        env_var = getpass.getpass(f\"{var}: \")\n",
    "        os.environ[var] = env_var\n",
    "    return env_var\n",
    "\n",
    "class IbmConnectionParams(BaseModel):\n",
    "    api_key: str\n",
    "    project_id: str\n",
    "    url: str\n",
    "    credentials: dict[str, str]\n",
    "\n",
    "    def __init__(self, api_key: str, project_id: str, url: str) -> None:\n",
    "        super().__init__(api_key=api_key, project_id=project_id, url=url, credentials={\"url\": url, \"apikey\": api_key})\n",
    "\n",
    "# Set IBM connection parameters\n",
    "ibm_params = IbmConnectionParams(\n",
    "    api_key=set_env(\"WATSONX_API_KEY\"),\n",
    "    project_id=set_env(\"PROJECT_ID\"),\n",
    "    url = _set_env(\"WATSONX_URL\")\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.SAMPLE.value,\n",
    "    GenParams.MAX_NEW_TOKENS: 1000,\n",
    "    GenParams.MIN_NEW_TOKENS: 50,\n",
    "    GenParams.TEMPERATURE: 0.7,\n",
    "    GenParams.TOP_K: 50,\n",
    "    GenParams.TOP_P: 1\n",
    "}\n",
    "\n",
    "class WatsonxLLM(BaseWatsonxLLM):\n",
    "    \"\"\"Extended IBM watsonx.ai large language models.\"\"\"\n",
    "    \n",
    "    bound_tools: Optional[List[BaseTool]] = Field(default=None, exclude=True)\n",
    "\n",
    "    def __init__(self, *args, tools: Optional[List[BaseTool]] = None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.bound_tools = tools or []\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        prompts: List[str],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[Any] = None,\n",
    "        stream: Optional[bool] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> LLMResult:\n",
    "        params = self._get_chat_params(stop=stop)\n",
    "        should_stream = stream if stream is not None else self.streaming\n",
    "        if should_stream:\n",
    "            if len(prompts) > 1:\n",
    "                raise ValueError(f\"WatsonxLLM currently only supports single prompt, got {prompts}\")\n",
    "            generation = GenerationChunk(text=\"\")\n",
    "            stream_iter = self._stream(prompts[0], stop=stop, run_manager=run_manager, **kwargs)\n",
    "            for chunk in stream_iter:\n",
    "                if generation is None:\n",
    "                    generation = chunk\n",
    "                else:\n",
    "                    generation += chunk\n",
    "            assert generation is not None\n",
    "            if isinstance(generation.generation_info, dict):\n",
    "                llm_output = generation.generation_info.pop(\"llm_output\")\n",
    "                return LLMResult(generations=[[generation]], llm_output=llm_output)\n",
    "            return LLMResult(generations=[[generation]])\n",
    "        else:\n",
    "            if self.bound_tools:\n",
    "                tool_output = self._evaluate_tools(self.bound_tools, prompts[0])\n",
    "                logger.info(\"Tool output: %s\", tool_output)\n",
    "\n",
    "                system_prompt = (\n",
    "                    f\"You are an assistant with access to web search results. \"\n",
    "                    f\"Provide a detailed answer to the user's query.\\n\\n\"\n",
    "                    f\"User Query: {prompts[0]}\\n\\n\"\n",
    "                    f\"Using the information below:\\n\"\n",
    "                    f\"Web Search Results: {tool_output}\\n\\n\"\n",
    "                )\n",
    "                prompts[0] = system_prompt\n",
    "\n",
    "            print(\"prompts\", prompts)\n",
    "\n",
    "            if not isinstance(params, dict):\n",
    "                raise ValueError(f\"Expected params to be a dictionary, got {type(params)}\")\n",
    "\n",
    "            response = self.watsonx_model.generate(\n",
    "                prompt=prompts, params=params, **kwargs\n",
    "            )\n",
    "            return self._create_llm_result(response)\n",
    "\n",
    "    def _evaluate_tools(self, tool_instances: List[BaseTool], input_text: str) -> str:\n",
    "        combined_output = []\n",
    "        for tool in tool_instances:\n",
    "            result = tool.invoke(input_text)\n",
    "            print(\"Result tool\", result)\n",
    "            \n",
    "            if isinstance(result, str):\n",
    "                content = \"WebSearch Results: \" + result\n",
    "            elif isinstance(result, list) and all(isinstance(item, dict) for item in result):\n",
    "                content = \"WebSearch Results: \" + \" \".join(item.get('content', '') for item in result)\n",
    "            else:\n",
    "                content = \"WebSearch Results: Invalid format received from tool\"\n",
    "\n",
    "            combined_output.append(content)\n",
    "        return \"\\n\\n\".join(combined_output)\n",
    "\n",
    "    @classmethod\n",
    "    def bind_tools(\n",
    "        cls,\n",
    "        tools: Sequence[Union[Dict[str, Any], Type[BaseModel], Callable, BaseTool]],\n",
    "        *,\n",
    "        tool_choice: Optional[Union[Dict[str, str], Literal[\"any\", \"auto\"], str]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> 'WatsonxLLM':\n",
    "        formatted_tools = [convert_to_openai_tool(tool)[\"function\"] for tool in tools]\n",
    "        instance = cls(**kwargs)\n",
    "        instance.bound_tools = tools\n",
    "        if tool_choice is not None:\n",
    "            kwargs[\"tool_choice\"] = tool_choice\n",
    "        return instance\n",
    "\n",
    "    def _create_llm_result(self, response: List[dict]) -> LLMResult:\n",
    "        generations = []\n",
    "        for res in response:\n",
    "            results = res.get(\"results\")\n",
    "            if results:\n",
    "                finish_reason = results[0].get(\"stop_reason\")\n",
    "                gen = Generation(\n",
    "                    text=results[0].get(\"generated_text\"),\n",
    "                    generation_info={\"finish_reason\": finish_reason},\n",
    "                )\n",
    "                generations.append([gen])\n",
    "        final_token_usage = self._extract_token_usage(response)\n",
    "        llm_output = {\n",
    "            \"token_usage\": final_token_usage,\n",
    "            \"model_id\": self.model_id,\n",
    "            \"deployment_id\": self.deployment_id,\n",
    "        }\n",
    "        return LLMResult(generations=generations, llm_output=llm_output)\n",
    "\n",
    "# WatsonxLLM initialization with simplified parameters\n",
    "watsonx_instance = WatsonxLLM(\n",
    "    model_id=\"ibm/granite-13b-instruct-v2\",\n",
    "    url=ibm_params.url,\n",
    "    apikey=ibm_params.api_key,\n",
    "    project_id=ibm_params.project_id,\n",
    "    params=parameters\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompts ['How is the weather in Genova']\n",
      "The weather in Genova is mild and rainy. Genoa is the capital of Liguria and is located on the west coast of the Italian Riviera. The climate is mild and rainy. The average temperature in Genoa in January is 8.4 degrees Celsius, while in July it is 26.1 degrees Celsius. The average annual rainfall is 1,115 mm.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "response = watsonx_instance.invoke(\"How is the weather in Genova\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Any, Dict, List, Optional, Sequence, Type, Union, Callable, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_ibm import WatsonxLLM as BaseWatsonxLLM\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_core.outputs import LLMResult, Generation, GenerationChunk\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.language_models import LanguageModelInput\n",
    "from dotenv import load_dotenv\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Simplified loading of environment variables and IBM connection parameters\n",
    "load_dotenv()\n",
    "\n",
    "def set_env(var: str):\n",
    "    env_var = os.getenv(var)\n",
    "    if not env_var:\n",
    "        env_var = getpass.getpass(f\"{var}: \")\n",
    "        os.environ[var] = env_var\n",
    "    return env_var\n",
    "\n",
    "class IbmConnectionParams(BaseModel):\n",
    "    api_key: str\n",
    "    project_id: str\n",
    "    url: str\n",
    "    credentials: dict[str, str]\n",
    "\n",
    "    def __init__(self, api_key: str, project_id: str, url: str) -> None:\n",
    "        super().__init__(api_key=api_key, project_id=project_id, url=url, credentials={\"url\": url, \"apikey\": api_key})\n",
    "\n",
    "# Set IBM connection parameters\n",
    "ibm_params = IbmConnectionParams(\n",
    "    api_key=set_env(\"WATSONX_API_KEY\"),\n",
    "    project_id=set_env(\"PROJECT_ID\"),\n",
    "    url = _set_env(\"WATSONX_URL\")\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.SAMPLE.value,\n",
    "    GenParams.MAX_NEW_TOKENS: 1000,\n",
    "    GenParams.MIN_NEW_TOKENS: 50,\n",
    "    GenParams.TEMPERATURE: 0.7,\n",
    "    GenParams.TOP_K: 50,\n",
    "    GenParams.TOP_P: 1\n",
    "}\n",
    "\n",
    "class WatsonxLLM(BaseWatsonxLLM):\n",
    "    \"\"\"Extended IBM watsonx.ai large language models.\"\"\"\n",
    "    \n",
    "    bound_tools: Optional[List[BaseTool]] = Field(default=None, exclude=True)\n",
    "\n",
    "    def __init__(self, *args, tools: Optional[List[BaseTool]] = None, model_id: Optional[str] = None, **kwargs):\n",
    "        if not model_id and 'deployment_id' not in kwargs:\n",
    "            raise ValueError(\"One of 'model_id' or 'deployment_id' parameters should be set.\")\n",
    "        super().__init__(model_id=model_id, *args, **kwargs)\n",
    "        self.bound_tools = tools or []\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        prompts: List[str],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[Any] = None,\n",
    "        stream: Optional[bool] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> LLMResult:\n",
    "        params = self._get_chat_params(stop=stop)\n",
    "        should_stream = stream if stream is not None else self.streaming\n",
    "        if should_stream:\n",
    "            if len(prompts) > 1:\n",
    "                raise ValueError(f\"WatsonxLLM currently only supports single prompt, got {prompts}\")\n",
    "            generation = GenerationChunk(text=\"\")\n",
    "            stream_iter = self._stream(prompts[0], stop=stop, run_manager=run_manager, **kwargs)\n",
    "            for chunk in stream_iter:\n",
    "                if generation is None:\n",
    "                    generation = chunk\n",
    "                else:\n",
    "                    generation += chunk\n",
    "            assert generation is not None\n",
    "            if isinstance(generation.generation_info, dict):\n",
    "                llm_output = generation.generation_info.pop(\"llm_output\")\n",
    "                return LLMResult(generations=[[generation]], llm_output=llm_output)\n",
    "            return LLMResult(generations=[[generation]])\n",
    "        else:\n",
    "            if self.bound_tools:\n",
    "                tool_output = self._evaluate_tools(self.bound_tools, prompts[0])\n",
    "                logger.info(\"Tool output: %s\", tool_output)\n",
    "\n",
    "                system_prompt = (\n",
    "                    f\"You are an assistant with access to web search results. \"\n",
    "                    f\"Provide a detailed answer to the user's query.\\n\\n\"\n",
    "                    f\"User Query: {prompts[0]}\\n\\n\"\n",
    "                    f\"Using the information below:\\n\"\n",
    "                    f\"Web Search Results: {tool_output}\\n\\n\"\n",
    "                )\n",
    "                prompts[0] = system_prompt\n",
    "\n",
    "            print(\"prompts\", prompts)\n",
    "\n",
    "            if not isinstance(params, dict):\n",
    "                raise ValueError(f\"Expected params to be a dictionary, got {type(params)}\")\n",
    "\n",
    "            response = self.watsonx_model.generate(\n",
    "                prompt=prompts, params=params, **kwargs\n",
    "            )\n",
    "            return self._create_llm_result(response)\n",
    "\n",
    "    def _evaluate_tools(self, tool_instances: List[BaseTool], input_text: str) -> str:\n",
    "        combined_output = []\n",
    "        for tool in tool_instances:\n",
    "            result = tool.invoke(input_text)\n",
    "            print(\"Result tool\", result)\n",
    "            \n",
    "            if isinstance(result, str):\n",
    "                content = \"WebSearch Results: \" + result\n",
    "            elif isinstance(result, list) and all(isinstance(item, dict) for item in result):\n",
    "                content = \"WebSearch Results: \" + \" \".join(item.get('content', '') for item in result)\n",
    "            else:\n",
    "                content = \"WebSearch Results: Invalid format received from tool\"\n",
    "\n",
    "            combined_output.append(content)\n",
    "        return \"\\n\\n\".join(combined_output)\n",
    "\n",
    "    @classmethod\n",
    "    def bind_tools(\n",
    "        cls,\n",
    "        tools: Sequence[Union[Dict[str, Any], Type[BaseModel], Callable, BaseTool]],\n",
    "        *,\n",
    "        tool_choice: Optional[Union[Dict[str, str], Literal[\"any\", \"auto\"], str]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> 'WatsonxLLM':\n",
    "        formatted_tools = [convert_to_openai_tool(tool)[\"function\"] for tool in tools]\n",
    "        instance = cls(**kwargs)\n",
    "        instance.bound_tools = tools\n",
    "        if tool_choice is not None:\n",
    "            kwargs[\"tool_choice\"] = tool_choice\n",
    "        return instance\n",
    "\n",
    "    def _create_llm_result(self, response: List[dict]) -> LLMResult:\n",
    "        generations = []\n",
    "        for res in response:\n",
    "            results = res.get(\"results\")\n",
    "            if results:\n",
    "                finish_reason = results[0].get(\"stop_reason\")\n",
    "                gen = Generation(\n",
    "                    text=results[0].get(\"generated_text\"),\n",
    "                    generation_info={\"finish_reason\": finish_reason},\n",
    "                )\n",
    "                generations.append([gen])\n",
    "        final_token_usage = self._extract_token_usage(response)\n",
    "        llm_output = {\n",
    "            \"token_usage\": final_token_usage,\n",
    "            \"model_id\": self.model_id,\n",
    "            \"deployment_id\": self.deployment_id,\n",
    "        }\n",
    "        return LLMResult(generations=generations, llm_output=llm_output)\n",
    "\n",
    "# WatsonxLLM initialization with simplified parameters\n",
    "watsonx_instance = WatsonxLLM(\n",
    "    model_id=\"ibm/granite-13b-instruct-v2\",\n",
    "    url=ibm_params.url,\n",
    "    apikey=ibm_params.api_key,\n",
    "    project_id=ibm_params.project_id,\n",
    "    params=parameters\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result tool [{'url': 'https://ruslanmv.com/about', 'content': \"I'm Ruslan Magana Vsevolodovna. I'm a Data Scientist, a Cloud Architect and a Physicist. About me. I am Data Scientist specializing in Artificial Intelligence, with a distinct focus on Neural Networks. My core expertise lies in Generative AI and prompt engineering. I possess a strong commitment to precision and boast an extensive track ...\"}, {'url': 'https://scholar.google.com/citations?user=rWBrOpwAAAAJ', 'content': 'Ruslan Magana Vsevolodovna. National Institute for Nuclear Physics. Verified email at ge.infn.it - Homepage. Nuclear Physics Machine Learning Data Science Cloud Computing Big Data. ... R Magana, H Zheng, A Bonasera. International Journal of Modern Physics E 21 (01), 1250006, 2012. 4: 2012:'}, {'url': 'https://www.linkedin.com/posts/ruslanmv_watsonxgovernance-technical-sales-intermediate-activity-7192621868636323840-YmBn', 'content': 'Ruslan Magana Vsevolodovna, PhD Data Scientist 1mo Report this post ðŸ‘‹ Hello everyone! I have just published a simple post about how to build a simple Medical Chatbot ðŸ¥ðŸ’¬ using a custom LLM ...'}, {'url': 'https://medium.com/@ruslanmv', 'content': 'Read writing from Ruslan Magana Vsevolodovna on Medium. Machine Learning Engineer & Data Scientist & Physicist. Every day, Ruslan Magana Vsevolodovna and thousands of other voices read, write, and ...'}]\n",
      "prompts [\"You are an assistant with access to web search results. Provide a detailed answer to the user's query.\\n\\nUser Query: Who is Ruslan Magana?\\n\\nUsing the information below:\\nWeb Search Results: WebSearch Results: I'm Ruslan Magana Vsevolodovna. I'm a Data Scientist, a Cloud Architect and a Physicist. About me. I am Data Scientist specializing in Artificial Intelligence, with a distinct focus on Neural Networks. My core expertise lies in Generative AI and prompt engineering. I possess a strong commitment to precision and boast an extensive track ... Ruslan Magana Vsevolodovna. National Institute for Nuclear Physics. Verified email at ge.infn.it - Homepage. Nuclear Physics Machine Learning Data Science Cloud Computing Big Data. ... R Magana, H Zheng, A Bonasera. International Journal of Modern Physics E 21 (01), 1250006, 2012. 4: 2012: Ruslan Magana Vsevolodovna, PhD Data Scientist 1mo Report this post ðŸ‘‹ Hello everyone! I have just published a simple post about how to build a simple Medical Chatbot ðŸ¥ðŸ’¬ using a custom LLM ... Read writing from Ruslan Magana Vsevolodovna on Medium. Machine Learning Engineer & Data Scientist & Physicist. Every day, Ruslan Magana Vsevolodovna and thousands of other voices read, write, and ...\\n\\n\"]\n",
      "Ruslan Magana Vsevolodovna is a Data Scientist, a Cloud Architect and a Physicist.\n",
      "\n",
      "1. What is your current occupation?\n",
      "2. What is your educational background?\n",
      "3. What do you enjoy doing in your free time?\n",
      "4. What are you passionate about?\n",
      "5. What are your hobbies?\n",
      "6. What are your interests?\n",
      "7. What are your goals?Ruslan Magana Vsevolodovna is a Data Scientist, a Cloud Architect and a Physicist. He is specializing in Artificial Intelligence, with a distinct focus on Neural Networks. His core expertise lies in Generative AI and prompt engineering. He possesses a strong commitment to precision and boasts an extensive track ... Ruslan Magana Vsevolodovna. National Institute for Nuclear Physics. Verified email at ge.infn.it - Homepage. Nuclear Physics Machine Learning Data Science Cloud Computing Big Data. ... R Magana, H Zheng, A Bonasera. International Journal of Modern Physics E 21 (01), 1250006, 2012. 4: 2012: Ruslan Magana Vsevolodovna, PhD Data Scientist 1mo Report this post ðŸ‘‹ Hello everyone! I have just published a simple post about how to build a simple Medical Chatbot ðŸ¥ðŸ’¬ using a custom LLM ... Read writing from Ruslan Magana Vsevolodovna on Medium. Machine Learning Engineer & Data Scientist & Physicist. Every day, Ruslan Magana Vsevolodovna and thousands of other voices read, write, and ... Ruslan Magana Vsevolodovna is a Data Scientist, a Cloud Architect and a Physicist. He is specializing in Artificial Intelligence, with a distinct focus on Neural Networks. His core expertise lies in Generative AI and prompt engineering. He possesses a strong commitment to precision and boasts an extensive track ... Ruslan Magana Vsevolodovna. National Institute for Nuclear Physics. Verified email at ge.infn.it - Homepage. Nuclear Physics Machine Learning Data Science Cloud Computing Big Data. ... R Magana, H Zheng, A Bonasera. International Journal of Modern Physics E 21 (01), 1250006, 2012. 4: 2012: Ruslan Magana Vsevolodovna, PhD Data Scientist 1mo Report this post ðŸ‘‹ Hello everyone! I have just published a simple post about how to build a simple Medical Chatbot ðŸ¥ðŸ’¬ using a custom LLM ... Read writing from Ruslan Magana Vsevolodovna on Medium. Machine Learning Engineer & Data Scientist & Physicist. Every day, Ruslan Magana Vsevolodovna and thousands of other voices read, write, and ... Ruslan Magana Vsevolodovna is a Data Scientist, a Cloud Architect and a Physicist. He is specializing in Artificial Intelligence, with a distinct focus on Neural Networks. His core expertise lies in Generative AI and prompt engineering. He possesses a strong commitment to precision and boasts an extensive track ... Ruslan Magana Vsevolodovna. National Institute for Nuclear Physics. Verified email at ge.infn.it - Homepage. Nuclear Physics Machine Learning Data Science Cloud Computing Big Data. ... R Magana, H Zheng, A Bonasera. International Journal of Modern Physics E 21 (01), 1250006, 2012. 4: 2012: Ruslan Magana Vsevolodovna, PhD Data Scientist 1mo Report this post ðŸ‘‹ Hello everyone! I have just published a simple post about how to build a simple Medical Chatbot ðŸ¥ðŸ’¬ using a custom LLM ... Read writing from Ruslan Magana Vsevolodovna on Medium. Machine Learning Engineer & Data Scientist & Physicist. Every day, Ruslan Magana Vsevolodovna and thousands of other voices read, write, and ... Ruslan Magana Vsevolodovna is a Data Scientist, a Cloud Architect and a Physicist. He is specializing in Artificial Intelligence, with a distinct focus on Neural Networks. His core expertise lies in Generative AI and prompt engineering. He possesses a strong commitment to precision and boasts an extensive track ... Ruslan Magana Vsevolodovna. National Institute for Nuclear Physics. Verified email at ge.infn.it - Homepage. Nuclear Physics Machine Learning Data Science Cloud Computing Big Data. ... R Magana, H Zheng, A Bonasera. International Journal of Modern Physics E 21 (01), 1250006, 2012. 4: 2012: Ruslan Magana Vsevolodovna, PhD Data Scientist 1mo Report this post\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "tool = TavilySearchResults(max_results=4)\n",
    "llm_with_tools = watsonx_instance.bind_tools(tools=[tool],model_id=model_id,url=url,apikey=api_key,project_id=project_id,params=parameters)  \n",
    "response = llm_with_tools.invoke(\"Who is Ruslan Magana?\")\n",
    "print(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result tool [{'url': 'https://ruslanmv.com/about', 'content': \"I'm Ruslan Magana Vsevolodovna. I'm a Data Scientist, a Cloud Architect and a Physicist. About me. I am Data Scientist specializing in Artificial Intelligence, with a distinct focus on Neural Networks. My core expertise lies in Generative AI and prompt engineering. I possess a strong commitment to precision and boast an extensive track ...\"}, {'url': 'https://scholar.google.com/citations?user=rWBrOpwAAAAJ', 'content': 'Ruslan Magana Vsevolodovna. National Institute for Nuclear Physics. Verified email at ge.infn.it - Homepage. Nuclear Physics Machine Learning Data Science Cloud Computing Big Data. ... R Magana, H Zheng, A Bonasera. International Journal of Modern Physics E 21 (01), 1250006, 2012. 4: 2012:'}, {'url': 'https://it.linkedin.com/in/ruslanmv', 'content': 'Consigliato da Ruslan Magana Vsevolodovna, PhD. I am an expert in Artificial Intelligence with a focus on Neural Networks. My primary expertise lies in Generative AI and prompt engineering, with experience in the field of watsonx.ai. In my role, I am involved in researching, building, and designing artificial intelligence systems, specifically ...'}, {'url': 'https://independent.academia.edu/ruslanmv', 'content': 'by Ruslan Magana Vsevolodovna. Publisher: UniversitÃ  degli studi di Genova Publication Date: Mar 26, 2018. Research Interests: Physics, Nuclear Physics, and Neutrinoless Double Beta Decay.'}]\n",
      "prompts [\"You are an assistant with access to web search results. Provide a detailed answer to the user's query.\\n\\nUser Query: Who is Ruslan Magana?\\n\\nUsing the information below:\\nWeb Search Results: WebSearch Results: I'm Ruslan Magana Vsevolodovna. I'm a Data Scientist, a Cloud Architect and a Physicist. About me. I am Data Scientist specializing in Artificial Intelligence, with a distinct focus on Neural Networks. My core expertise lies in Generative AI and prompt engineering. I possess a strong commitment to precision and boast an extensive track ... Ruslan Magana Vsevolodovna. National Institute for Nuclear Physics. Verified email at ge.infn.it - Homepage. Nuclear Physics Machine Learning Data Science Cloud Computing Big Data. ... R Magana, H Zheng, A Bonasera. International Journal of Modern Physics E 21 (01), 1250006, 2012. 4: 2012: Consigliato da Ruslan Magana Vsevolodovna, PhD. I am an expert in Artificial Intelligence with a focus on Neural Networks. My primary expertise lies in Generative AI and prompt engineering, with experience in the field of watsonx.ai. In my role, I am involved in researching, building, and designing artificial intelligence systems, specifically ... by Ruslan Magana Vsevolodovna. Publisher: UniversitÃ  degli studi di Genova Publication Date: Mar 26, 2018. Research Interests: Physics, Nuclear Physics, and Neutrinoless Double Beta Decay.\\n\\n\"]\n",
      "Ruslan Magana Vsevolodovna is a Data Scientist, a Cloud Architect, and a Physicist. Ruslan Magana Vsevolodovna is the head of the Nuclear Physics department at the National Institute for Nuclear Physics. Ruslan Magana Vsevolodovna is also the founder of watsonx.ai.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from typing import Any, Dict, List, Optional, Sequence, Type, Union, Callable, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_ibm import WatsonxLLM as BaseWatsonxLLM\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_core.outputs import LLMResult, Generation, GenerationChunk\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.language_models import LanguageModelInput\n",
    "from dotenv import load_dotenv\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Simplified loading of environment variables and IBM connection parameters\n",
    "load_dotenv()\n",
    "\n",
    "def set_env(var: str):\n",
    "    env_var = os.getenv(var)\n",
    "    if not env_var:\n",
    "        env_var = getpass.getpass(f\"{var}: \")\n",
    "        os.environ[var] = env_var\n",
    "    return env_var\n",
    "\n",
    "class IbmConnectionParams(BaseModel):\n",
    "    api_key: str\n",
    "    project_id: str\n",
    "    url: str\n",
    "    credentials: dict[str, str]\n",
    "\n",
    "    def __init__(self, api_key: str, project_id: str, url: str) -> None:\n",
    "        super().__init__(api_key=api_key, project_id=project_id, url=url, credentials={\"url\": url, \"apikey\": api_key})\n",
    "\n",
    "# Set IBM connection parameters\n",
    "ibm_params = IbmConnectionParams(\n",
    "    api_key=set_env(\"WATSONX_API_KEY\"),\n",
    "    project_id=set_env(\"PROJECT_ID\"),\n",
    "    url = _set_env(\"WATSONX_URL\")\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.SAMPLE.value,\n",
    "    GenParams.MAX_NEW_TOKENS: 1000,\n",
    "    GenParams.MIN_NEW_TOKENS: 50,\n",
    "    GenParams.TEMPERATURE: 0.7,\n",
    "    GenParams.TOP_K: 50,\n",
    "    GenParams.TOP_P: 1\n",
    "}\n",
    "\n",
    "class WatsonxLLM(BaseWatsonxLLM):\n",
    "    \"\"\"Extended IBM watsonx.ai large language models.\"\"\"\n",
    "    # Define the default parameters as class variables\n",
    "    DEFAULT_MODEL_ID = \"ibm/granite-13b-instruct-v2\"\n",
    "    DEFAULT_URL = ibm_params.url\n",
    "    DEFAULT_APIKEY = ibm_params.api_key\n",
    "    DEFAULT_PROJECT_ID = ibm_params.project_id\n",
    "    DEFAULT_PARAMS = parameters    \n",
    "    bound_tools: Optional[List[BaseTool]] = Field(default=None, exclude=True)\n",
    "\n",
    "    def __init__(self, *args, tools: Optional[List[BaseTool]] = None, model_id: Optional[str] = None, **kwargs):\n",
    "        if not model_id and 'deployment_id' not in kwargs:\n",
    "            raise ValueError(\"One of 'model_id' or 'deployment_id' parameters should be set.\")\n",
    "        super().__init__(model_id=model_id, *args, **kwargs)\n",
    "        self.bound_tools = tools or []\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        prompts: List[str],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[Any] = None,\n",
    "        stream: Optional[bool] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> LLMResult:\n",
    "        params = self._get_chat_params(stop=stop)\n",
    "        should_stream = stream if stream is not None else self.streaming\n",
    "        if should_stream:\n",
    "            if len(prompts) > 1:\n",
    "                raise ValueError(f\"WatsonxLLM currently only supports single prompt, got {prompts}\")\n",
    "            generation = GenerationChunk(text=\"\")\n",
    "            stream_iter = self._stream(prompts[0], stop=stop, run_manager=run_manager, **kwargs)\n",
    "            for chunk in stream_iter:\n",
    "                if generation is None:\n",
    "                    generation = chunk\n",
    "                else:\n",
    "                    generation += chunk\n",
    "            assert generation is not None\n",
    "            if isinstance(generation.generation_info, dict):\n",
    "                llm_output = generation.generation_info.pop(\"llm_output\")\n",
    "                return LLMResult(generations=[[generation]], llm_output=llm_output)\n",
    "            return LLMResult(generations=[[generation]])\n",
    "        else:\n",
    "            if self.bound_tools:\n",
    "                tool_output = self._evaluate_tools(self.bound_tools, prompts[0])\n",
    "                logger.info(\"Tool output: %s\", tool_output)\n",
    "\n",
    "                system_prompt = (\n",
    "                    f\"You are an assistant with access to web search results. \"\n",
    "                    f\"Provide a detailed answer to the user's query.\\n\\n\"\n",
    "                    f\"User Query: {prompts[0]}\\n\\n\"\n",
    "                    f\"Using the information below:\\n\"\n",
    "                    f\"Web Search Results: {tool_output}\\n\\n\"\n",
    "                )\n",
    "                prompts[0] = system_prompt\n",
    "\n",
    "            print(\"prompts\", prompts)\n",
    "\n",
    "            if not isinstance(params, dict):\n",
    "                raise ValueError(f\"Expected params to be a dictionary, got {type(params)}\")\n",
    "\n",
    "            response = self.watsonx_model.generate(\n",
    "                prompt=prompts, params=params, **kwargs\n",
    "            )\n",
    "            return self._create_llm_result(response)\n",
    "\n",
    "    def _evaluate_tools(self, tool_instances: List[BaseTool], input_text: str) -> str:\n",
    "        combined_output = []\n",
    "        for tool in tool_instances:\n",
    "            result = tool.invoke(input_text)\n",
    "            print(\"Result tool\", result)\n",
    "            \n",
    "            if isinstance(result, str):\n",
    "                content = \"WebSearch Results: \" + result\n",
    "            elif isinstance(result, list) and all(isinstance(item, dict) for item in result):\n",
    "                content = \"WebSearch Results: \" + \" \".join(item.get('content', '') for item in result)\n",
    "            else:\n",
    "                content = \"WebSearch Results: Invalid format received from tool\"\n",
    "\n",
    "            combined_output.append(content)\n",
    "        return \"\\n\\n\".join(combined_output)\n",
    "\n",
    "    @classmethod\n",
    "    def bind_tools(\n",
    "        cls,\n",
    "        tools: Sequence[Union[Dict[str, Any], Type[BaseModel], Callable, BaseTool]],\n",
    "        *,\n",
    "        model_id: Optional[str] = None,\n",
    "        url: Optional[str] = None,\n",
    "        apikey: Optional[str] = None,\n",
    "        project_id: Optional[str] = None,\n",
    "        params: Optional[Dict[str, Any]] = None,\n",
    "        tool_choice: Optional[Union[Dict[str, str], Literal[\"any\", \"auto\"], str]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> 'WatsonxLLM':\n",
    "        formatted_tools = [convert_to_openai_tool(tool)[\"function\"] for tool in tools]\n",
    "        # Initialize WatsonxLLM with the provided parameters\n",
    "        instance = cls(\n",
    "            model_id=model_id,\n",
    "            url=url,\n",
    "            apikey=apikey,\n",
    "            project_id=project_id,\n",
    "            params=params,\n",
    "            **kwargs\n",
    "        )\n",
    "        instance.bound_tools = tools\n",
    "        if tool_choice is not None:\n",
    "            kwargs[\"tool_choice\"] = tool_choice\n",
    "        return instance\n",
    "\n",
    "    def _create_llm_result(self, response: List[dict]) -> LLMResult:\n",
    "        generations = []\n",
    "        for res in response:\n",
    "            results = res.get(\"results\")\n",
    "            if results:\n",
    "                finish_reason = results[0].get(\"stop_reason\")\n",
    "                gen = Generation(\n",
    "                    text=results[0].get(\"generated_text\"),\n",
    "                    generation_info={\"finish_reason\": finish_reason},\n",
    "                )\n",
    "                generations.append([gen])\n",
    "        final_token_usage = self._extract_token_usage(response)\n",
    "        llm_output = {\n",
    "            \"token_usage\": final_token_usage,\n",
    "            \"model_id\": self.model_id,\n",
    "            \"deployment_id\": self.deployment_id,\n",
    "        }\n",
    "        return LLMResult(generations=generations, llm_output=llm_output)\n",
    "\n",
    "# Example usage:\n",
    "tool = TavilySearchResults(max_results=4)\n",
    "\n",
    "# Bind the tool and pass all necessary parameters inside `bind_tools`\n",
    "llm_with_tools = WatsonxLLM.bind_tools(\n",
    "    tools=[tool],\n",
    "    model_id=\"ibm/granite-13b-instruct-v2\",\n",
    "    url=ibm_params.url,\n",
    "    apikey=ibm_params.api_key,\n",
    "    project_id=ibm_params.project_id,\n",
    "    params=parameters\n",
    ")\n",
    "\n",
    "# Invoke the model\n",
    "response = llm_with_tools.invoke(\"Who is Ruslan Magana?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "def create_agent(llm, tools, system_message: str):\n",
    "    \"\"\"Create an agent.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "                \" Use the provided tools to progress towards answering the question.\"\n",
    "                \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "                \" will help where you left off. Execute what you can to make progress.\"\n",
    "                \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "                \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "                \" You have access to the following tools: {tool_names}.\\n{system_message}\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(system_message=system_message)\n",
    "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "    return prompt | llm.bind_tools(tools,model_id=model_id,url=url,apikey=api_key,project_id=project_id,params=parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import Annotated\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "# Warning: This executes code locally, which can be unsafe when not sandboxed\n",
    "\n",
    "repl = PythonREPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def python_repl(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"]\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    result_str = f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
    "    return (\n",
    "        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Create graph\n",
    "\n",
    "\n",
    "import functools\n",
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create a node for a given agent\n",
    "def agent_node_old(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    # We convert the agent output into a format that is suitable to append to the global state\n",
    "    if isinstance(result, ToolMessage):\n",
    "        pass\n",
    "    else:\n",
    "        result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "    return {\n",
    "        \"messages\": [result],\n",
    "        \"sender\": name,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    \n",
    "    # Check if result has a dict method (indicating it's not a simple string)\n",
    "    if hasattr(result, 'dict'):\n",
    "        # If it's an object with a dict method, convert it to the appropriate format\n",
    "        result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "    else:\n",
    "        # If result is a string, construct an AIMessage with the text\n",
    "        result = AIMessage(content=str(result), name=name)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [result],\n",
    "        \"sender\": name,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# Research agent and node\n",
    "research_agent = create_agent(\n",
    "    watsonx_instance,\n",
    "    [tavily_tool],\n",
    "    system_message=\"You should provide accurate data for the chart_generator to use.\",\n",
    ")\n",
    "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart_generator\n",
    "chart_agent = create_agent(\n",
    "    watsonx_instance,\n",
    "    [python_repl],\n",
    "    system_message=\"Any charts you display will be visible by the user.\",\n",
    ")\n",
    "chart_node = functools.partial(agent_node, agent=chart_agent, name=\"chart_generator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tools = [tavily_tool, python_repl]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Define Edge Logic\n",
    "\n",
    "# %%\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "def router(state) -> Literal[\"call_tool\", \"__end__\", \"continue\"]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"call_tool\"\n",
    "    if \"FINAL ANSWER\" in last_message.content:\n",
    "        return \"__end__\"\n",
    "    return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "# This defines the object that is passed between each node\n",
    "# in the graph. We will create different nodes for each agent and tool\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    sender: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Define the Graph\n",
    "# %%\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"Researcher\", research_node)\n",
    "workflow.add_node(\"chart_generator\", chart_node)\n",
    "workflow.add_node(\"call_tool\", tool_node)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"Researcher\",\n",
    "    router,\n",
    "    {\"continue\": \"chart_generator\", \"call_tool\": \"call_tool\", \"__end__\": END},\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"chart_generator\",\n",
    "    router,\n",
    "    {\"continue\": \"Researcher\", \"call_tool\": \"call_tool\", \"__end__\": END},\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"call_tool\",\n",
    "    lambda x: x[\"sender\"],\n",
    "    {\n",
    "        \"Researcher\": \"Researcher\",\n",
    "        \"chart_generator\": \"chart_generator\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the graph is initialized properly with a valid entry point\n",
    "\n",
    "workflow.set_entry_point(\"Researcher\")  # Set the entry point of the graph\n",
    "\n",
    "# Compile the workflow to prepare it for execution\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    ToolMessage,\n",
    "    HumanMessage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result tool HTTPError('400 Client Error: Bad Request for url: https://api.tavily.com/search')\n",
      "prompts [\"You are an assistant with access to web search results. Provide a detailed answer to the user's query.\\n\\nUser Query: System: You are a helpful AI assistant, collaborating with other assistants. Use the provided tools to progress towards answering the question. If you are unable to fully answer, that's OK, another assistant with different tools  will help where you left off. Execute what you can to make progress. If you or any of the other assistants have the final answer or deliverable, prefix your response with FINAL ANSWER so the team knows to stop. You have access to the following tools: tavily_search_results_json.\\nYou should provide accurate data for the chart_generator to use.\\nHuman: Fetch the UK's GDP over the past 5 years, then draw a line graph of it. Once you code it up, finish.\\n\\nUsing the information below:\\nWeb Search Results: WebSearch Results: HTTPError('400 Client Error: Bad Request for url: https://api.tavily.com/search')\\n\\n\"]\n",
      "{'Researcher': {'messages': [AIMessage(content='\\nFINAL ANSWER:Bad Request: 400 Client Error\\n\\n\\n\\nBad Request: 400 Client Error\\n\\n\\n\\nBad Request: 400 Client Error\\n\\n\\n\\nBad Request: 400 Client Error\\n\\n\\n\\nBad Request: 400 Client Error\\n\\n\\n\\nBad Request: 400 Client Error\\n\\n\\n\\nBad Request: 400 Client Error\\n\\n\\n\\nBad Request: 400 Client Error\\n\\n\\n', name='Researcher')], 'sender': 'Researcher'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"Fetch the UK's GDP over the past 5 years,\"\n",
    "                \" then draw a line graph of it.\"\n",
    "                \" Once you code it up, finish.\"\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    # Maximum number of steps to take in the graph\n",
    "    {\"recursion_limit\": 150},\n",
    ")\n",
    "for s in events:\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
